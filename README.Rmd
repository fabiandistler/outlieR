---
output: github_document
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  out.width = "100%"
)
```

# outlieR

<!-- badges: start -->
<!-- badges: end -->

> Automatic Outlier Detection Using Isolation Forests


## Ãœbersicht

`outlieR` bietet eine einfache, leistungsstarke API zur automatischen Erkennung von AusreiÃŸern in tabellarischen Daten. Das Package nutzt Isolation Forests (via `isotree`) mit automatischem Hyperparameter-Tuning und liefert detaillierte Diagnosen auf Feature-Ebene.

### Hauptfeatures

âœ¨ **Einfache API** - Eine Funktion fÃ¼r die meisten AnwendungsfÃ¤lle
ğŸ¯ **Automatisches Tuning** - Grid Search, Random Search oder Bayesian Optimization  
ğŸ“Š **Detaillierte Diagnostik** - Feature-Level Outlier-Analyse
ğŸ“ˆ **Umfangreiche Visualisierungen** - Score-Plots, Feature Importance, PCA-Projektion
ğŸ”§ **Flexibel** - UnterstÃ¼tzt numerische und kategoriale Variablen

## Installation

```{r,eval=FALSE}
# Von GitHub installieren (Development Version)
# install.packages("remotes")
remotes::install_github("fabiandistler/outlieR")

# Von CRAN installieren (sobald verfÃ¼gbar)
# install.packages("outlieR")
```

## Quick Start

```{r}
library(outlieR)

# Basis-Verwendung: Automatische Outlier-Erkennung
result <- detect_outliers(mtcars)

# Ergebnisse anzeigen
print(result)
summary(result)

# Outlier-Details extrahieren
outlier_summary <- get_outlier_summary(result)
head(outlier_summary)

# Visualisierungen erstellen
plot(result, type = "score") # Score-Verteilung
plot(result, type = "features") # Feature Importance
plot(result, type = "pca") # PCA-Projektion
```

## Detaillierte Beispiele

### 1. Spezifische Spalten analysieren

```{r}
# Nur ausgewÃ¤hlte Variablen verwenden
result <- detect_outliers(
  data = iris,
  target_cols = c("Sepal.Length", "Sepal.Width", "Petal.Length"),
  contamination = 0.05 # Erwarte 5% Outliers
)
```

### 2. Ohne automatisches Tuning

```{r}
# Manuelle Parameter-Spezifikation fÃ¼r mehr Kontrolle
result <- detect_outliers(
  data = mtcars,
  tune = FALSE,
  n_trees = 200,
  max_depth = 12,
  sample_size = 512
)
```

### 3. Verschiedene Tuning-Methoden

```{r,eval=FALSE}
# Grid Search (default, systematisch aber langsamer)
result_grid <- detect_outliers(mtcars, tune_method = "grid")

# Random Search (schneller, gute Ergebnisse)
result_random <- detect_outliers(mtcars, tune_method = "random")

# Bayesian Optimization (experimentell)
result_bayes <- detect_outliers(mtcars, tune_method = "bayesian")
```

### 4. Mit kategorischen Variablen

```{r}
# Automatische One-Hot-Encoding von Faktoren
set.seed(42)
data <- data.frame(
  value1 = rnorm(100),
  value2 = rnorm(100),
  category = sample(c("A", "B", "C"), 100, replace = TRUE)
)

result <- detect_outliers(data)
```

### 5. Detaillierte Outlier-Analyse

```{r,}
result <- detect_outliers(mtcars)

# Welche Features sind in Zeile 31 auffÃ¤llig?
detailed <- get_outlier_summary(result, detailed = TRUE)
detailed[row_id == 31]
```



## Performance

```{r,eval=FALSE}
# Benchmark auf verschiedenen DatengrÃ¶ÃŸen
library(bench)

# Kleiner Datensatz (1000 Zeilen)
small_data <- data.frame(matrix(rnorm(1000 * 10), ncol = 10))
mark(detect_outliers(small_data, tune = FALSE))
# ~500ms

# Mittlerer Datensatz (10000 Zeilen)
medium_data <- data.frame(matrix(rnorm(10000 * 10), ncol = 10))
mark(detect_outliers(medium_data, tune = FALSE))
# ~2s

# Mit Tuning (langsamer, aber bessere Ergebnisse)
mark(detect_outliers(medium_data, tune = TRUE, tune_method = "random"))
# ~20s (parallel auf 4 Cores)
```

## Erweiterte Verwendung

### Custom-Threshold

```{r,eval=FALSE}
result <- detect_outliers(mtcars, contamination = 0.05)

# Eigenen Threshold verwenden
custom_threshold <- quantile(result$scores, 0.99)
custom_outliers <- result$scores > custom_threshold

# Neue Details generieren
result$outliers <- custom_outliers
result$threshold <- custom_threshold
```

## Troubleshooting

### Zu viele/wenige Outliers

```{r,eval=FALSE}
# Contamination-Parameter anpassen
result <- detect_outliers(data, contamination = 0.05) # Weniger Outliers
result <- detect_outliers(data, contamination = 0.15) # Mehr Outliers
```

### Schlechte Trennung

```{r,eval=FALSE}
# Mehr BÃ¤ume verwenden
result <- detect_outliers(data, n_trees = 300)

# Tuning aktivieren fÃ¼r bessere Parameter
result <- detect_outliers(data, tune = TRUE, tune_method = "random")
```

### Memory-Probleme bei groÃŸen Daten

```{r,eval=FALSE}
# Paralleles Processing deaktivieren
result <- detect_outliers(large_data, parallel = FALSE)

# Weniger BÃ¤ume
result <- detect_outliers(large_data, n_trees = 50, tune = FALSE)
```



## Mitwirken

Contributions sind willkommen! Bitte:

1. Fork das Repository
2. Erstelle einen Feature-Branch (`git checkout -b feature/AmazingFeature`)
3. Committe deine Ã„nderungen (`git commit -m 'Add some AmazingFeature'`)
4. Push zum Branch (`git push origin feature/AmazingFeature`)
5. Ã–ffne einen Pull Request

## Lizenz

MIT License - siehe [LICENSE](LICENSE) Datei fÃ¼r Details.


## Danksagungen

- `isotree` Package fÃ¼r die Isolation Forest Implementierung
- R Community fÃ¼r Feedback und Inspiration
